{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.backend.tensorflow_backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendefinisikan Fungsi\n",
    "def set_gpu_mem_alloc(mem_use):\n",
    "    avail  = 4041\n",
    "    percent = mem_use / avail\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = percent\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tf.Session(config=config))\n",
    "\n",
    "set_gpu_mem_alloc(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:10000]\n",
    "y_train = y_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fecc41461d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flatten 28*28 images to a 784 vector for each image\n",
    "# num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "# X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "# X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train[:10000]\n",
    "y_train = y_train[:10000]\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def getcnn():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 93,418\n",
      "Trainable params: 93,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = getcnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 7s - loss: 0.2872 - acc: 0.9135 - val_loss: 0.1073 - val_acc: 0.9667\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.0952 - acc: 0.9695 - val_loss: 0.1048 - val_acc: 0.9677\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.0575 - acc: 0.9822 - val_loss: 0.0745 - val_acc: 0.9771\n",
      "Epoch 4/10\n",
      " - 6s - loss: 0.0401 - acc: 0.9870 - val_loss: 0.0814 - val_acc: 0.9732\n",
      "Epoch 5/10\n",
      " - 7s - loss: 0.0268 - acc: 0.9918 - val_loss: 0.0657 - val_acc: 0.9793\n",
      "Epoch 6/10\n",
      " - 9s - loss: 0.0251 - acc: 0.9913 - val_loss: 0.0736 - val_acc: 0.9778\n",
      "Epoch 7/10\n",
      " - 7s - loss: 0.0152 - acc: 0.9951 - val_loss: 0.0781 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 7s - loss: 0.0168 - acc: 0.9943 - val_loss: 0.0895 - val_acc: 0.9737\n",
      "Epoch 9/10\n",
      " - 6s - loss: 0.0104 - acc: 0.9973 - val_loss: 0.0728 - val_acc: 0.9812\n",
      "Epoch 10/10\n",
      " - 8s - loss: 0.0111 - acc: 0.9970 - val_loss: 0.0957 - val_acc: 0.9750\n",
      "Baseline Error: 2.50%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=10, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hasil_training_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 592,074\n",
      "Trainable params: 592,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_test.shape[1] * X_test.shape[2]\n",
    "Test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "print(Test[10].shape)\n",
    "test = model.predict(Test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fecd4783ac8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed04686390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx= 1\n",
    "print(test[idx])\n",
    "print(y_test[idx])\n",
    "plt.imshow(X_test[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlearn]",
   "language": "python",
   "name": "conda-env-dlearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
